# Batch processing for IoT using HDInsight and Hive

This chapter describes using HDInsight to perform batch processing in an IoT solution. As described in the [Introduction](./index.md) to this series, the Drone Delivery application uses batch processing to analyze data about deliveries. For example, batch processing can answer questions like "How long does the average delivery take?" or "How many deliveries failed to be completed?" More complex analyses could correlate this information with external data such as weather data.

A *delivery* is a business entity, but from the perspective of the drone, a delivery is a sequence of events: Picking up a package, flying to the destination, and dropping off the package. During the flight, the drone sends its current position at regular intervals. The batch processing job needs to assemble this event sequence into a meaningful business entity for analysis.

## The batch processing pipeline

For batch processing, you should capture and store the raw device telemetry before doing any processing. By keeping the raw data, you can always run new queries to get new insights into the data. If you filter or aggregate the raw data before storing it, then you lose information that might prove valuable later.

To capture the messages from IoT Hub, add a custom endpoint that routes to Azure Blob storage. For more information, see [Save IoT hub messages that contain sensor data to your Azure blob storage](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-store-data-in-azure-table-storage). The data is written in batches and stored in containers grouped by Event Hub partition and date (year, month, day, hour, minute). The data is written to blob storage in Avro format.

Next, the data is processed by a series of Hive queries. The first step is to create external tables. An external table is a table where the data resides outside of outside of Hive (in this case, blob). The table metadata is stored in Hive. This allows Hive to understand the format of the data. 

```sql
CREATE EXTERNAL TABLE rawtelemetry
  ROW FORMAT SERDE
  'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
  STORED AS INPUTFORMAT
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
  OUTPUTFORMAT
  'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
  LOCATION
  'wasbs://telemetry@<your storage account>.blob.core.windows.net/<your IoT Hub name>/'
  TBLPROPERTIES (
    'avro.schema.url'='wasbs://telemetry@<your storage account>.blob.core.windows.net/telemetry.avsc');
```

The table schema is defined by an Avro schema file, which is generated by running Avro tools against a sample data file. 

The next step is a Hive query that loads the data from external tables into Hive. This steps also converts the external tables into a format that is easier for processing.

```sql
INSERT INTO TABLE enrichedtelemetrytable
SELECT * FROM (
    SELECT
        get_json_object(telemetryjson,'$.occurrenceUtcTime') AS occurrenceUtcTime,
        get_json_object(telemetryjson,'$.deviceId') AS deviceId,	  
        get_json_object(telemetryjson,'$.sensorType') AS sensorType,
        get_json_object(telemetryjson,'$.deliveryId') AS deliveryId,
        get_json_object(telemetryjson,'$.velocity') AS velocity,
        get_json_object(telemetryjson,'$.acceleration') AS acceleration,
        split(get_json_object(telemetryjson,'$.position'),'\\|')[0] AS latitude,
        split(get_json_object(telemetryjson,'$.position'),'\\|')[1] AS longitude,
        split(get_json_object(telemetryjson,'$.position'),'\\|')[2] AS altitude,
        array('DPS', 'INF', 'PUP', 'DOP', 'ARS')[cast(get_json_object(telemetryjson,'$.flightStatus') AS int)] AS flightStatus
	    --Flight Status Codes: 1) Depart station, 2) In flight, 3) Picked up package, 4) Dropped off package, 5) Arrived at station
    FROM (
	    SELECT cast(body as string) AS telemetryjson FROM rawtelemetry
    ) sub1
) sub2
WHERE sensorType LIKE 'drone-event-sensor%'
```

This query has three nested SELECT statements

- The inner SELECT statement coerces the body of the Avro message into a string.

- The next SELECT statement splits the raw JSON string into separate columns. In addition, it splits the `position` field into separate latitude, longitude, and altitude values. Finally, it converts the `flightStatus` field from an integer into a value that is more meaningful to the backend business systems, which use three-letter codes for flight status.

- The outer SELECT contains a WHERE clause that selects `drone-event-sensor` messages, filtering out other message types.

Here's what the data looks like after this processing step:

| occurrenceutctime	| deviceid | sensortype | deliveryid | velocity | acceleration | latitude | longitude | altitude | flightstatus |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 6/7/2018 2:32:29 PM | drone-01.4467 | drone-event-sensor;v1 | 00a8907c-6e9c-495a-af12-99f315df46ee | 58.69 | 2.49 | 47.603006 | -122.004185 | 494.99 | DPS |
| 6/7/2018 2:32:34 + PM | drone-01.4467 | drone-event-sensor;v1 | 00a8907c-6e9c-495a-af12-99f315df46ee | 59.3 | 2.5 | 47.603008 | 122.00414 | 494.98 | INF |
| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |
| 6/7/2018 2:42:44 PM | drone-01.4467 | drone-event-sensor;v1 | 00a8907c-6e9c-495a-af12-99f315df46ee | 60.3 | 2.5 | 47.678758 | -121.891975 | 494.99 | DOP |

The final HIVE query finds matching start/stop events for each deilvery:

```sql
INSERT INTO TABLE deliverysummarytable
SELECT deliveryId, max(startDateTime) as startDate, max(completeDateTime) as completeDate
FROM (
    SELECT deliveryId,
        CASE
            WHEN flightStatus == 'DPS' --Departed Station
                THEN occurrenceUtcTime
                ELSE null
            END AS startDateTime,
        CASE
            WHEN flightStatus == 'DOP' --Dropped off Package
                THEN occurrenceUtcTime
                ELSE null
            END AS completeDateTime
    FROM enrichedtelemetrytable
    WHERE flightStatus == 'DPS' OR flightStatus == 'DOP'
) sub
GROUP BY deliveryId
```
Every flight event has an `occurrenceUtcTime` field, which is the time stamp of the event. The query shown above projects this value either to `startDateTime` or to `completeDataTime`, depending on whether the flight status for the event is 'DPS' (departed station) or 'DOP' (dropped off package). Then it groups the events by their delivery ID.

Here's what the data looks like after the last processing step:

| deliveryid | startdate | completedate |
|------------|-----------|--------------|
| 00a8907c-6e9c-495a-af12-99f315df46ee | 6/7/2018 2:32:29 PM | 6/7/2018 2:42:44 PM |

At this point, you can load the table into Excel or Power BI for analysis. However, Hive tables can only be read while the HDInsights cluster is running. Therefore, typically you would copy the output to another data store such as CosmosDB, to be used by a serving layer.

## Incremental processing

Whenever you create a new Hive query, you will run it over a set of historical data. 
As new data comes in, one option is simply to re-run the query over the entire data set. That will take longer as the data set continues to grow, however, and may become impractical.   

Often, it's possible to perform incremental processing by running the job on a schedule and processing just the new data. You'll need to consider how to merge the data sets, and what happens at the boundaries. For example, in our scenario, we are processing deliveries and looking for start and end times. If you run on the previous day's data, what happens to a delivery that starts before midnight and is completed the following day?

## Storage considerations

When choosing a data store for the raw telemetry, consider these factors:

- Storing raw telemetry requires high write throughput 
- The data is append-only. Records are never updated after being written.
- Writing can be done in batches for efficiency.
- Reads will be full scans, not singleton lookups.
- The data should be partitioned by time intervals (for example, by hour) so that you can run incremental batch jobs over a specified time span.
- Storage should be redundant to guard against possible data loss.
- Must be compatible with your batch processing layer. 

Blob storage meets all of these requirements. For storing the raw telemetry data, we recommend using General-purpose v2 storage. Pricing for GPv2 accounts has been designed to deliver the lowest per gigabyte prices. In addition, GPv2 storage supports [hot, cool, and archive tiers](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers). The hot is optimized for frequently accessed data, the cool tier is optimized for infrequently accessed data, and the archive tier is optimized for data that is rarely accessed but needs to be archived.

Consider the following tiering strategy:

- Store incoming telemetry in the hot tier for batch processing. 
- After a period of time (say, 1 month), move blobs to cool tier. Cool storage offers similar latency to hot storage, on the order of milliseconds. However, the cost it optimized for storage versus data retrieval, making it useful for longer-term storage of data that is less frequently accessed.
- Very old data (say, 3 years) can be moved to archive storage. Archive storage is much less expensive, but has a retrieval time of several hours, so don't use this tier if you expect to run on-demand queries over the data.

Note that changing tiers incurs a one-time cost, so you shouldn't frequently switch a blob between tiers. Your organization may also have retention policies for regulatory and compliance reasons. 

Another storage option to consider is Azure Data Lake Store, if you need any of the more advanced features that Data Lake Store offers such as POSIX ACLs to grant file-level permissions. See [Comparing Azure Data Lake Store and Azure Blob Storage](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-comparison-with-blob-storage). However, also be aware that Data Lake Store is currently available in a limited number of regions. 



